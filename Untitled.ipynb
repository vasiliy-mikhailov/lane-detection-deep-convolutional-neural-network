{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane detection using deep convolutional neural network autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting this project, I have a hypothesis that deep convolutional neural network will be able to find road structure.\n",
    "\n",
    "Then I will label real road videos and will test it on video from Udacity. I expect to find train videos on youtube and I expect that 1 000 labeled images will be enough for success. I estimate labeling effort as highest effort in whole project - I expect to spend ~11 hours on this, labeling 90 images per hour (2 images per minute for 45 minutes and 15 minutes rest).\n",
    "\n",
    "To find out how good model is and how many actual images I need, I will solve simplier task first: I will first prove simplier hypothesis: sumulate a bunch of road images and will train dCNN autoencoder to recognize it from image back to model.\n",
    "\n",
    "I will simulate only one lane (in which car is currently moving) for purpose of simplicity.\n",
    "\n",
    "Udacity challenge has three videos:\n",
    "1. \"project_video.mp4\" has solid yellow left line and dash-dot white right line. Lines are curved with one curve direction or straight \n",
    "2. \"challenge_video.mp4\" same as previous but with changing lightning conditions\n",
    "3. \"harder_challenge_video.mp4\" has double solid yellow left line and solid right line, lighning conditions are changing very fast. Lines are curved with two extremums (which means it cannot be described with parabola, but with cubic polynomial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x: float, y: float):\n",
    "        self.x: float = x\n",
    "        self.y: float = y\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"({}, {})\".format(self.x, self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.25, 0.75)\n"
     ]
    }
   ],
   "source": [
    "point = Point(x=0.25, y=0.75)\n",
    "print(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedLine:\n",
    "    def __init__(self, polynomial_coefficients: [float]):\n",
    "        self.polynomial_coefficients: [float] = polynomial_coefficients\n",
    "    \n",
    "    def __str__(self):\n",
    "        polynomial_coefficients = self.polynomial_coefficients\n",
    "        polynomial_equation_parts = []\n",
    "        for index, polynomial_coefficient in enumerate(polynomial_coefficients):\n",
    "            degree = len(polynomial_coefficients) - index - 1\n",
    "            \n",
    "            if degree > 1:\n",
    "                polynomial_equation_part = \"{}*x^{}\".format(polynomial_coefficient, degree)\n",
    "            if degree == 1:\n",
    "                polynomial_equation_part = \"{}*x\".format(polynomial_coefficient)\n",
    "            elif degree == 0:\n",
    "                polynomial_equation_part = \"{}\".format(polynomial_coefficient)\n",
    "                \n",
    "            polynomial_equation_parts.append(polynomial_equation_part)\n",
    "        \n",
    "        return \"+\".join(polynomial_equation_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0*x^3+0.5*x^2+0.25*x+0.125\n"
     ]
    }
   ],
   "source": [
    "simulated_line = SimulatedLine(polynomial_coefficients=[1.0, 0.5, 0.25, 0.125])\n",
    "print(simulated_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatedLane(Parabola):\n",
    "    /*\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lane:\n",
    "    def __init__(self, left_line: PolyLine, right_line: PolyLine):\n",
    "        self.left_line: PolyLine = left_line\n",
    "        self.right_line: PolyLine = right_line\n",
    "            \n",
    "    def __str__(self):\n",
    "        return \"left line: {}\\nright line: {}\".format(self.left_line, self.right_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane = Lane(\n",
    "    left_line=PolyLine(a=0.5, b=0.25, c=0.125),\n",
    "    right_line=PolyLine(a=0.75, b=0.5, c=0.25)\n",
    ")\n",
    "\n",
    "print(lane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneInput:\n",
    "    def __init__(self, img):\n",
    "        self.img = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneRecognizeInteractor:\n",
    "    def __init__(self):\n",
    "        self.model = load_model() \n",
    "        \n",
    "    def interact(self, lane_input) -> :\n",
    "        model.predict(...)\n",
    "        return lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanePresenter:\n",
    "    def __init__(self, lane: Lane, image):\n",
    "        self.lane: Lane = lane\n",
    "            \n",
    "    def present():\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class ImagePairGenerator:\n",
    "    def __init__(self, image_width: int, image_height: int):\n",
    "        self.image_width: int = image_width\n",
    "        self.image_height: int = image_height\n",
    "            \n",
    "    def make_blank_image(self, width: int, height: int):\n",
    "        return np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    def put_value_in_boundaries(self, value: int, max_value: int):\n",
    "        if value > max_value:\n",
    "            return max_value\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "    def draw_poly_line(self, image, points: [Point]):\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "\n",
    "        thickness = 1\n",
    "\n",
    "        points_list = np.array([[\n",
    "            self.put_value_in_boundaries(value=int(point.x * width), max_value=width - thickness), \n",
    "            self.put_value_in_boundaries(value=int(point.y * height), max_value=height - thickness)\n",
    "        ] for point in points])\n",
    "\n",
    "        cv2.polylines(image, [points_list], isClosed=True, color=[0, 255, 0], thickness=thickness)\n",
    "\n",
    "    def draw_filled_poly_line(self, image, points: [Point]):\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "\n",
    "        points_list = np.array([[int(point.x * width), int(point.y * height)] for point in points])\n",
    "\n",
    "        cv2.fillPoly(image, [points_list], color=[0, 255, 0])\n",
    "\n",
    "    def generate_random_poly_line(self):\n",
    "        left_bottom_x = 0.5 - random.uniform(0, 0.5)\n",
    "        left_bottom = Point(x=left_bottom_x, y=1)\n",
    "\n",
    "        left_top_x = 0.5 - random.uniform(0, 0.5)\n",
    "        left_top = Point(x=left_top_x, y=0)\n",
    "\n",
    "        right_top_x = 0.5 + random.uniform(0, 0.5)\n",
    "        right_top = Point(x=right_top_x, y=0)\n",
    "\n",
    "        right_bottom_x = 0.5 + random.uniform(0, 0.5)\n",
    "        right_bottom = Point(x=right_bottom_x, y=1)\n",
    "\n",
    "        return [\n",
    "            left_bottom,\n",
    "            left_top,\n",
    "            right_top,\n",
    "            right_bottom\n",
    "        ]\n",
    "\n",
    "    def generate(self):\n",
    "        image_width = self.image_width\n",
    "        image_height = self.image_height\n",
    "                \n",
    "        poly_line = self.generate_random_poly_line()\n",
    "\n",
    "        X_image = self.make_blank_image(width=image_width, height=image_height)\n",
    "        self.draw_poly_line(image=X_image, points=poly_line)\n",
    "\n",
    "        y_image = self.make_blank_image(width=image_width, height=image_height)\n",
    "        self.draw_filled_poly_line(image=y_image, points=poly_line)\n",
    "\n",
    "        return X_image, y_image\n",
    "\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "image_pair_generator = ImagePairGenerator(image_width=image_width, image_height=image_height)\n",
    "X_image, y_image = image_pair_generator.generate()\n",
    "\n",
    "plt.imshow(X_image)\n",
    "plt.show()\n",
    "plt.imshow(y_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_image(image, file_name: str):\n",
    "    pil_image = Image.fromarray(image)\n",
    "    pil_image.save(file_name)\n",
    "    \n",
    "save_image(image=X_image, file_name='X.png')\n",
    "save_image(image=y_image, file_name='y.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_data(image_width: int, image_height: int, image_quantity: int, folder: str):\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "    os.makedirs('./data/{}'.format(folder), exist_ok=True)\n",
    "    os.makedirs('./data/{}/X'.format(folder), exist_ok=True)\n",
    "    os.makedirs('./data/{}/y'.format(folder), exist_ok=True)\n",
    "    \n",
    "    image_pair_generator = ImagePairGenerator(image_width=image_width, image_height=image_height)\n",
    "    for i in range(image_quantity):\n",
    "        X_image, y_image = image_pair_generator.generate()\n",
    "        save_image(image=X_image, file_name='./data/{}/X/{:05}.png'.format(folder, i))\n",
    "        save_image(image=y_image, file_name='./data/{}/y/{:05}.png'.format(folder, i))\n",
    "        \n",
    "def generate_train_data(image_width: int, image_height: int):\n",
    "    generate_data(image_width=image_width, image_height=image_height, image_quantity=500, folder='train')\n",
    "        \n",
    "generate_train_data(image_width=image_width, image_height=image_height)\n",
    "\n",
    "def generate_valid_data(image_width: int, image_height: int):\n",
    "    generate_data(image_width=image_width, image_height=image_height, image_quantity=100, folder='valid')\n",
    "        \n",
    "generate_valid_data(image_width=image_width, image_height=image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(image_width: int, image_height: int):\n",
    "    generate_data(image_width=image_width, image_height=image_height, image_quantity=100, folder='test')\n",
    "        \n",
    "generate_test_data(image_width=image_width, image_height=image_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder: str):\n",
    "    result = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        image = cv2.imread(os.path.join(folder, filename))\n",
    "        result.append(image)\n",
    "    return np.array(result)\n",
    "    \n",
    "X_train = load_images(folder='./data/train/X') / 255.0\n",
    "y_train = load_images(folder='./data/train/y') / 255.0\n",
    "\n",
    "X_valid = load_images(folder='./data/valid/X') / 255.0\n",
    "y_valid = load_images(folder='./data/valid/y') / 255.0\n",
    "\n",
    "X_test = load_images(folder='./data/test/X') / 255.0\n",
    "y_test = load_images(folder='./data/test/y') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "def create_model(input_shape, pool_size):\n",
    "    # Create the actual neural network here\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Below layers were re-named for easier reading of model summary; this not necessary\n",
    "    # Conv Layer 1\n",
    "    model.add(layers.Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "    # Conv Layer 2\n",
    "    model.add(layers.Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "    # Pooling 1\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 3\n",
    "    model.add(layers.Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 4\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 5\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Pooling 2\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 6\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 7\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Pooling 3\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Upsample 1\n",
    "    model.add(layers.UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 1\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Deconv 2\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Upsample 2\n",
    "    model.add(layers.UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 3\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Deconv 4\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Deconv 5\n",
    "    model.add(layers.Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Upsample 3\n",
    "    model.add(layers.UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 6\n",
    "    model.add(layers.Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "\n",
    "    # Final layer - only including one channel so 1 filter\n",
    "    model.add(layers.Conv2DTranspose(3, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_fixed(input_shape, pool_size):\n",
    "    # Create the actual neural network here\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Below layers were re-named for easier reading of model summary; this not necessary\n",
    "    # Conv Layer 1\n",
    "    model.add(layers.Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "    # Conv Layer 2\n",
    "    model.add(layers.Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "    # Pooling 1\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "\n",
    "    # Conv Layer 4\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 5\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Pooling 2\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Conv Layer 6\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Conv Layer 7\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Pooling 3\n",
    "    model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # Upsample 1\n",
    "    model.add(layers.UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 1\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Deconv 2\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Upsample 2\n",
    "    model.add(layers.UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 3\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # Deconv 4\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "    # Upsample 3\n",
    "    model.add(layers.UpSampling2D(size=pool_size))\n",
    "\n",
    "    # Deconv 6\n",
    "    model.add(layers.Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "    \n",
    "    # Deconv 6\n",
    "    #model.add(layers.Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv7'))\n",
    "\n",
    "    # Final layer - only including one channel so 1 filter\n",
    "    model.add(layers.Conv2DTranspose(3, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_2():\n",
    "    # Create the actual neural network here\n",
    "    model = models.Sequential()\n",
    "\n",
    "    filters = [16, 32, 64]\n",
    "    \n",
    "    for filter in filters:\n",
    "        model.add(layers.Conv2D(filter, (3, 3), padding='valid', strides=(1,1), activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Conv2D(filter, (3, 3), padding='valid', strides=(1,1), activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(1,1)))\n",
    "\n",
    "    filters_in_reverse_order = filters[::-1]\n",
    "    for filter in filters_in_reverse_order:\n",
    "        model.add(layers.UpSampling2D(size=(1,1)))\n",
    "        model.add(layers.Conv2DTranspose(filter, (3, 3), padding='valid', strides=(1,1), activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Conv2DTranspose(filter, (3, 3), padding='valid', strides=(1,1), activation = 'relu'))\n",
    "        model.add(layers.Dropout(0.2))        \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (3, 3), padding='valid', strides=(1,1), activation = 'relu'))\n",
    "\n",
    "    return model\n",
    "\n",
    "class Fill(Model):\n",
    "    def __init__(self, image_width: int, image_height: int):\n",
    "        super(Fill, self).__init__()\n",
    "        number_of_channels = 3\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(image_height, image_width, number_of_channels, )),\n",
    "            layers.Conv2D(8, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(8, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(8, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(16, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(16, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(16, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(32, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(32, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(32, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(64, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(64, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(64, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "#             layers.Conv2D(128, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Activation(activation='relu'),\n",
    "#             layers.Conv2D(128, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Activation(activation='relu'),\n",
    "#             layers.Conv2D(128, (3,3), activation=None, padding='same', strides=(1, 1)),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Activation(activation='relu'),\n",
    "#             layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "#             layers.Conv2D(128, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Activation(activation='relu'),\n",
    "#             layers.Conv2D(128, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Activation(activation='relu'),\n",
    "#             layers.Conv2D(128, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Activation(activation='relu'),\n",
    "#             layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(64, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(64, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(32, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(32, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(32, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(16, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(16, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(16, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(8, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(8, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.Conv2D(8, kernel_size=3, strides=(1, 1), activation=None, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(activation='relu'),\n",
    "            layers.UpSampling2D((2, 2)),\n",
    "            layers.Conv2D(number_of_channels, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "fill_autoencoder = Fill(image_width=image_width, image_height=image_height)\n",
    "#fill_autoencoder = create_model(input_shape=(image_height, image_width, 3, ), pool_size=(1, 1))\n",
    "#fill_autoencoder = create_model_fixed(input_shape=(image_height, image_width, 3, ), pool_size=(1, 1))\n",
    "#fill_autoencoder = create_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
    "fill_autoencoder.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = X_train[0]\n",
    "plt.imshow(X_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "reduce_learning_rate_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.75,\n",
    "    patience=3,\n",
    "    min_delta=1e-5, \n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=1e-5, \n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "fill_autoencoder.fit(X_train, y_train,\n",
    "                epochs=1000,\n",
    "                shuffle=True,\n",
    "                batch_size=2,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                verbose=1, \n",
    "                callbacks=[\n",
    "                    reduce_learning_rate_callback,\n",
    "                    early_stopping_callback,\n",
    "                    #ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_delta=1e-5, mode='min')\n",
    "                ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fill_autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "plt.imshow(X_test[i])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(y_test[i])\n",
    "plt.show()\n",
    "\n",
    "prediction = y_pred[i]\n",
    "plt.imshow(prediction, vmin=0.0, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
